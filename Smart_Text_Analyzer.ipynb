{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TozOiJk2TNtO"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract pillow transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Function to extract text from an image using Tesseract\n",
        "def extract_text_from_image(image_path):\n",
        "    # Open the image using PIL\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Use Tesseract to do OCR on the image\n",
        "    text = pytesseract.image_to_string(image)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "image_path = 'path_to_your_image.png'\n",
        "extracted_text = extract_text_from_image(image_path)\n",
        "print(\"Extracted Text:\", extracted_text)\n"
      ],
      "metadata": {
        "id": "EpsTMsppTm3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to preprocess the extracted text\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove any special characters\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Example usage\n",
        "preprocessed_text = preprocess_text(extracted_text)\n",
        "print(\"Preprocessed Text:\", preprocessed_text)\n"
      ],
      "metadata": {
        "id": "RnzNlPyeTrJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Function to answer questions based on the given context using a pre-trained LLM\n",
        "def answer_question(question, context):\n",
        "    # Load the pre-trained question-answering pipeline\n",
        "    qa_pipeline = pipeline('question-answering', model='distilbert-base-uncased-distilled-squad')\n",
        "\n",
        "    # Get the answer from the model\n",
        "    answer = qa_pipeline({'question': question, 'context': context})\n",
        "\n",
        "    return answer['answer']\n",
        "\n",
        "# Example usage\n",
        "question = \"What is the name of the product?\"\n",
        "answer = answer_question(question, preprocessed_text)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "1cFBJ5_VTtuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ocr_question_answering_pipeline(image_path, question):\n",
        "    # Step 1: Extract text from image\n",
        "    extracted_text = extract_text_from_image(image_path)\n",
        "\n",
        "    # Step 2: Preprocess the extracted text\n",
        "    preprocessed_text = preprocess_text(extracted_text)\n",
        "\n",
        "    # Step 3: Use LLM to answer the question\n",
        "    answer = answer_question(question, preprocessed_text)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Example usage\n",
        "image_path = 'path_to_your_image.png'\n",
        "question = \"What is the name of the product?\"\n",
        "answer = ocr_question_answering_pipeline(image_path, question)\n",
        "print(\"Final Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "o6e5yPbsTv0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}